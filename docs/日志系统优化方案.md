# 日志系统优化方案

## 当前问题分析

### 1. 性能问题
- ❌ **同步写入**：当前使用同步 `write()` 方法，会阻塞主线程
- ❌ **无缓冲**：每条日志立即写入，频繁的 I/O 操作
- ❌ **重复格式化**：`formatMessage` 被调用两次（控制台和文件）

### 2. 功能缺失
- ❌ **无结构化日志**：只有文本格式，不便于分析和查询
- ❌ **无敏感信息过滤**：可能泄露密码、token 等敏感信息
- ❌ **无日志压缩**：旧日志文件占用大量空间
- ❌ **无采样机制**：高频日志可能产生过多日志
- ❌ **错误处理不足**：文件写入失败时没有降级方案

### 3. 可维护性
- ❌ **无日志查询API**：无法通过接口查询日志
- ❌ **无性能监控**：不知道日志系统本身的性能影响

## 优化方案

### 优先级 P0（必须优化）

#### 1. 异步批量写入 ✅
**问题**：同步写入阻塞主线程，影响性能

**方案**：
- 使用异步写入队列
- 批量写入（每 100ms 或 100 条日志）
- 使用 `fs.promises` 或 `stream.write()` 的异步模式

**收益**：
- 减少 I/O 阻塞
- 提高系统吞吐量
- 降低日志写入对业务的影响

#### 2. 敏感信息过滤 ✅
**问题**：日志可能包含密码、token 等敏感信息

**方案**：
- 自动检测并替换敏感字段
- 支持配置敏感字段列表
- 支持自定义过滤函数

**收益**：
- 提高安全性
- 符合数据保护要求

#### 3. 结构化日志（JSON格式）✅
**问题**：文本格式不便于分析和查询

**方案**：
- 支持 JSON 格式输出
- 保留文本格式作为默认（向后兼容）
- 通过环境变量切换格式

**收益**：
- 便于日志分析工具处理
- 支持日志聚合服务（ELK、Loki等）
- 便于查询和过滤

### 优先级 P1（重要优化）

#### 4. 日志压缩和归档 ✅
**问题**：旧日志文件占用大量磁盘空间

**方案**：
- 自动压缩 7 天前的日志文件
- 归档到 `logs/archive/` 目录
- 支持配置压缩和归档策略

**收益**：
- 节省磁盘空间
- 保留历史日志便于审计

#### 5. 错误处理和降级 ✅
**问题**：文件写入失败时没有处理

**方案**：
- 捕获写入错误
- 降级到仅控制台输出
- 记录错误到系统日志

**收益**：
- 提高系统稳定性
- 避免因日志问题导致服务崩溃

#### 6. 日志采样 ✅
**问题**：高频日志可能产生过多日志

**方案**：
- 支持按比例采样（如 10%）
- 支持按时间间隔采样
- 错误日志始终记录（不采样）

**收益**：
- 减少日志量
- 降低 I/O 压力
- 保留关键信息

### 优先级 P2（可选优化）

#### 7. 日志查询 API
**方案**：
- 提供 REST API 查询日志
- 支持按时间、级别、上下文过滤
- 支持分页和排序

#### 8. 性能监控
**方案**：
- 记录日志写入延迟
- 记录队列长度
- 记录写入失败次数

#### 9. 日志聚合集成
**方案**：
- 支持直接输出到日志聚合服务
- 支持多种格式（JSON、Logstash、Loki）
- 支持批量发送

## 实施计划

### 第一阶段：核心优化（P0）
1. ✅ 实现异步批量写入
2. ✅ 实现敏感信息过滤
3. ✅ 实现结构化日志（JSON格式）

### 第二阶段：重要优化（P1）
4. ✅ 实现日志压缩和归档
5. ✅ 实现错误处理和降级
6. ✅ 实现日志采样

### 第三阶段：可选优化（P2）
7. 实现日志查询 API
8. 实现性能监控
9. 集成日志聚合服务

## 预期收益

### 性能提升
- **I/O 阻塞减少**：90%+（异步批量写入）
- **日志写入延迟**：降低 80%+
- **系统吞吐量**：提升 10-20%

### 功能增强
- **安全性**：敏感信息自动过滤
- **可维护性**：结构化日志便于分析
- **存储效率**：压缩节省 70%+ 空间

### 稳定性
- **错误处理**：完善的降级机制
- **资源管理**：自动压缩和清理
- **采样机制**：避免日志爆炸

